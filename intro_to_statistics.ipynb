{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/distributions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson Objectives:\n",
    "\n",
    "By the end of this lesson students will be able to:\n",
    "\n",
    "1. Describe the difference between discrete vs continuous variables\n",
    "2. Describe the difference between PMFs, PDFs, CDFs\n",
    "3. Explain the relationship between the bernouli and binomial distributions\n",
    "4. Explain the qualities of th normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a statistical distribution?\n",
    "\n",
    "> After establishing the set of all possible outcomes, a statistical distribution is a representation of the relative frequency each event will occur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The distributions we introduce today will reappear throughout the bootcamp.  They will:\n",
    "\n",
    "1. Allow us to select appropriate statistical tests to judge the validity of our conclusions.  As a data scientist at your company, you may be asked to perform various scientific tests. For example, you may be asked to judge whether a certain change to the user interface of your website increases conversion rate. \n",
    "2. Provide the foundation for specific assumptions of linear regression.\n",
    "3. Appear in the cost functions tied to logistic regression and other models.\n",
    "4. Drive the classification decisions made in parametric models, such as Naive-Bayes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. Discrete vs Continuous\n",
    "\n",
    "We will learn about a variety of different probability distributions, but before we do so, we need to establish the difference between **discrete** and **continuous** variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Variables\n",
    ">  With discrete distributions, the values can only take a finite set of values.  Take, for example, a roll of a single six-sided die. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/uniform.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - There are 6 possible outcomes of the roll.  In other words, 4.5 cannot be an outcome. As you see on the PMF plot, the bars which represent probability do not touch, suggesting non-integer numbers between 1 and 6 are not possible results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above plot visualizes an **empirical** distribution. Empirical distributions are based on observations of real world phenomena. \n",
    "\n",
    "An a**nalytical** distribution is one which is created by a mathematical function.  We use analytical functions to model real world phenomena. \n",
    "[ThinkStats2e](http://greenteapress.com/thinkstats2/html/thinkstats2006.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's think back to our Phase 1 projects: What are some examples of discrete variables distributions in the Movie datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of analytical discrete distributions:\n",
    "\n",
    "> 1. The Uniform Distribution:- occurs when all possible outcomes are equally likely.\n",
    "> 2. The Bernoulli Distribution: - represents the probability of success for a certain experiment (binary outcome).\n",
    "> 3. The Binomial Distribution - represents the probability of observing a specific number of successes (Bernoulli trials) in a specific number of trials.\n",
    "> 4. The Poisson Distribution:- represents the probability of ð‘› events in a given time period when the overall rate of occurrence is constant.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Variables\n",
    "\n",
    "With a continuous distribution, the set of possible results is an infinite set of values within a range. One way to think about continuous variables are variables that have been measured.  Measurement can always be more precise.\n",
    "\n",
    "> - A common example is height.  Although we think of height often in values such as 5 feet 7 inches, the exact height of a person can be any value within the range of possible heights.  In other words, a person could be 5 foot 7.000001 inches tall. \n",
    "> - Another example is temperature, as shown below:\n",
    "\n",
    "![](images/pdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of analytical continuous distributions\n",
    "> 1. Continuous uniform\n",
    "> 2. The Normal or Gaussian distribution.\n",
    "> 3. Exponential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are examples of continuous variables the movie datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "The distinction between discrete and continuous is very important to have in your mind, and can easily be seen in plots. \n",
    "\n",
    "Let's do a quick exercise. There are two tasks.  \n",
    "\n",
    "1. First, simply change the color of the plots representing discrete data to orange and the plots represent continuous data to blue.\n",
    "2. Attach the titles to the distributions you think reflect the data set described."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "title_1 = \"height_of_us_women in inches\"\n",
    "title_2 = 'outcomes of flipping a coin 100 times'\n",
    "title_3 = 'outcomes of rolling a 20 sided die 1000 times'\n",
    "title_4 = 'probability that a computer part lasts a certain amount of time from now.'\n",
    "title_5 = 'probability that a picture is a chihauhua\\n, a muffin, a bird, or a piece of pizza\\n as would guess a neural network'\n",
    "title_6 = 'probability of rolling a value equal to or below\\n a certain number on a 20 sided dice'\n",
    "no_title = 'no_title'\n",
    "\n",
    "fig, ax = plt.subplots(2,3, figsize=(15,10))\n",
    "\n",
    "sns.kdeplot(np.random.exponential(10, size=1000), ax=ax[0][0], color='purple')\n",
    "ax[0][0].set_xlim(0,80)\n",
    "ax[0][0].set_title(no_title)\n",
    "\n",
    "sns.barplot(['outcome_1', 'outcome_2', 'outcome_3', 'outcome_4'], [.4,.5,.08,.02], ax=ax[1][0], color='yellow')\n",
    "ax[1][0].tick_params(labelrotation=45)\n",
    "ax[1][0].set_title(no_title)\n",
    "\n",
    "sns.kdeplot(np.random.normal(64.5, 2.5, 1000), ax=ax[1][1])\n",
    "ax[1][1].set_title(no_title)\n",
    "\n",
    "sns.barplot(x=['outcome_1','outcome_2'], y=[sum(np.random.binomial(1,.5, 100)),100 - sum(np.random.binomial(1,.5, 100))], ax=ax[0][1], color='pink')\n",
    "ax[0][1].set_title(no_title)\n",
    "\n",
    "sns.barplot(x=list(range(1,21)), y=np.unique(np.random.randint(1,21,1000), return_counts=True)[1], ax=ax[0][2], color='teal')\n",
    "ax[0][2].tick_params(labelrotation=45)\n",
    "ax[0][2].set_title(no_title)\n",
    "\n",
    "sns.barplot(list(range(1,21)), np.cumsum([1/20 for number in range(1,21)]), ax=ax[1][2])\n",
    "ax[1][2].set_title(no_title)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PMFs, PDFs, and CDFs, oh my!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMF: Probability Mass Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $\\bf{probability\\ mass\\ function\\ (pmf)}$ for a random variable gives, at any value $k$, the probability that the random variable takes the value $k$. Suppose, for example, that I have a jar full of lottery balls containing:\n",
    "- 50 \"1\"s,\n",
    "- 25 \"2\"s,\n",
    "- 15 \"3\"s,\n",
    "- 10 \"4\"s\n",
    "\n",
    "We then represent this function in a plot like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each number, we calculate the probability that pull it from the jar by dividing\n",
    "\n",
    "numbers = range(1,5)\n",
    "counts = [50,25, 15, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the probs by dividing each count by the total number of balls.\n",
    "probs = [count/sum(counts) for count in counts]\n",
    "lotto_dict = {number: prob  for number, prob in zip(numbers, probs)}\n",
    "lotto_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot here!\n",
    "\n",
    "\n",
    "x = list(lotto_dict.keys())\n",
    "y = list(lotto_dict.values())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.plot(x, y, 'bo', ms=8, label='lotto pmf')\n",
    "ax.vlines(x, 0, y, 'r', lw=5)\n",
    "ax.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **uniform** distribution describes a set of discrete outcomes whose probabilities are all equally likely.\n",
    "\n",
    "A common example of this distribution is found with a deck of cards.  Each of the 4 types of cards (heart, spade, club, and diamond) have an equal chance of being drawn from a deck of cards at random.\n",
    "\n",
    "![](https://37.media.tumblr.com/ee7000bd2e867ae2c518fe4462f85b80/tumblr_n5w7lseFZj1s2wio8o1_400.gif)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the pmf for the 4 card type outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF: Probability Density Function\n",
    "> Probability density functions are similar to PMFs, in that they describe the probability of a result within a range of values.  But where PMFs can be descibed with barplots, PDFs are smooth curves.  \n",
    "\n",
    "![](./images/pdf_temp.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think of a pdf as a bunch of bars of probabilities getting smaller and smaller until each neighbor is indistinguishable from its neighbor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/pdf_inter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Describing the PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The mean** of our PDF affects where it is **centered** on the x-axis.  In numpy and stats, mean is denoted by the loc parameter.\n",
    "\n",
    "The two plots below have the same shape, but different centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean = 0\n",
    "z_curve = np.linspace(stats.norm(mean,1).ppf(0.01),\n",
    "             stats.norm(mean,1).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean,1).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve')\n",
    "\n",
    "mean = 1\n",
    "z_curve = np.linspace(stats.norm(mean,1).ppf(0.01),\n",
    "             stats.norm(mean,1).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean,1).pdf(z_curve),\n",
    "     'b-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "ax.set_title(\"Two distributions differing only in mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The variance** of our plots describes how **closely the points are gathered around the mean**.  Low variance means tight and skinny, high variance short and wide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mess around with the variance to see how the shape is altered.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "mean = 1\n",
    "var = 1\n",
    "z_curve = np.linspace(stats.norm(mean,var).ppf(0.01),\n",
    "             stats.norm(mean,var).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean,var).pdf(z_curve),\n",
    "     'r-', lw=5, alpha=0.6, label='z_curve')\n",
    "\n",
    "mean = 1\n",
    "var = 3\n",
    "z_curve = np.linspace(stats.norm(mean,var).ppf(0.01),\n",
    "             stats.norm(mean,var).ppf(0.99), 100)\n",
    "ax.plot(z_curve, stats.norm(mean,var).pdf(z_curve),\n",
    "     'b-', lw=5, alpha=0.6, label='norm pdf')\n",
    "\n",
    "ax.set_title(\"Two distributions with different variance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skew \n",
    "\n",
    "We will touch briefly on the third and fourth moments for the normal curve. Skew is a measure of assymemtry.  A skew of zero is perfectly symetrical about the mean.   \n",
    "![skew](./images/skew.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can check skew with scipy\n",
    "z_curve = np.random.normal(0,1, 1000)\n",
    "print(stats.skew(z_curve))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualizing the skew\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(z_curve);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add right skew to the data, let's add some outliers to the left of the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn about skew, let's take a normal distribution, and add values to skew it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update add right skew with data to skew it.\n",
    "z_curve = np.random.normal(0,1, 1000)\n",
    "add_right_skew = [-6]\n",
    "right_skewed_data = np.concatenate([z_curve, add_right_skew])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(right_skewed_data)\n",
    "ax.set_title(f\"Negative Skew {stats.skew(right_skewed_data)}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, do the same for left skewed data\n",
    "\n",
    "z_curve = np.random.normal(0,1, 1000)\n",
    "add_left_skew = [6]\n",
    "left_skewed_data = np.concatenate([z_curve, add_left_skew])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(left_skewed_data)\n",
    "ax.set_title(f\"Positive Skew {stats.skew(left_skewed_data)}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kurtosis\n",
    "\n",
    "Kurtosis is a measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution. \n",
    "\n",
    "![kurtosis](https://mvpprograms.com/help/images/KurtosisPict.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CDF: Cumulative Distribution Function\n",
    "\n",
    "![](./images/cdf.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **cumulative distribution function(cdf)** describes the **probability that your result will be of a value equal to or below a certain value**. It can apply to both discrete or continuous functions.\n",
    "\n",
    "For the lottery example above, the CDF would describe the probability of drawing a ball equal to or below a certain number.  \n",
    "\n",
    "In order to create the CDF from a sample, we:\n",
    "- align the values from least to greatest\n",
    "- for each value, count the number of values that are less than or equal to the current value\n",
    "- divide that count by the total number of values\n",
    "\n",
    "The CDF of the Lotto example plots how likely we are to get a ball less than or equal to a given example. \n",
    "\n",
    "Let's create the CDF for our Lotto example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# align the values\n",
    "lotto_dict = {0:0, 1:50, 2:25, 3:15, 4:10}\n",
    "values = list(lotto_dict.keys())\n",
    "# count the number of values that are less than or equal to the current value\n",
    "count_less_than_equal = np.cumsum(list(lotto_dict.values()))\n",
    "# divide by total number of values\n",
    "prob_less_than_or_equal = count_less_than_equal/sum(lotto_dict.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's plot our CDF\n",
    "\n",
    "fix, ax = plt.subplots()\n",
    "ax.bar(values, prob_less_than_or_equal, width=1)\n",
    "\n",
    "ax.set_title('Lotto CDF')\n",
    "\n",
    "x_tick_values = list(range(0,6))\n",
    "x_tick_pos = [tick-.5 for tick in x_tick_values]\n",
    "\n",
    "ax.set_xticks(x_tick_pos)\n",
    "ax.set_xticklabels(x_tick_values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continues variable CDF\n",
    "\n",
    "- For continuous random variables, obtaining probabilities for observing a specific outcome is not possible \n",
    "- Have to be careful with interpretation of PDF\n",
    "\n",
    "We can, however, use the CDF to learn the probability that a variable will be less than or equal to a given value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following normal distributions of heights (more on the normal distribution below).\n",
    "\n",
    "The PDF and the CDF look like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sorted(stats.norm.rvs(loc=70,scale=3,size=1000))\n",
    "r_cdf = stats.norm.cdf(r, loc=70, scale=3)\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize=(10,5))\n",
    "sns.kdeplot(r, ax=ax1, shade=True)\n",
    "ax1.set_title('PDF of Male Height in US')\n",
    "\n",
    "ax2.plot(r, r_cdf, color='g')\n",
    "ax2.set_title('CDF of Male Height in the US')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we provide numpy with the underlying parameters of our distribution, we can calculate: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the probability that a value falls below a specified value\n",
    "r = stats.norm(70,3)\n",
    "r.cdf(73)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the probability that a value falls between two specified values\n",
    "r = stats.norm(70,3)\n",
    "r.cdf(73) - r.cdf(67)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the value associated with a specfic percentile:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.ppf(.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from there, the value of ranges, such as the interquartile range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'interquartile range {r.ppf(.25)} - {r.ppf(.75)}')\n",
    "\n",
    "# We can see that the boxplot's interquartile range aligns with our ppf calculation above\n",
    "box = plt.boxplot(stats.norm.rvs(loc=70,scale=3,size=1000));\n",
    "print(box['boxes'][0].get_data())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Bernouli and Binomial Distributions\n",
    "\n",
    "The Bernouli distribution is the discrete distribution that describes a two-outcome trial, such as heads or tails.  The distribution is described by the probability of one random variable of the value 1 associated with the probability p, and its correlary, the probability q, associated with 0  and taking the probability 1-p. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest example is, once again, a coin flip.  In this scenario, we define either heads or tails as a \"success\", and assume, if the coin is fair, the probability of success to be .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/bernouli.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the bernoulli distribution the mean is $p$ \n",
    "\n",
    "In the bernoulli distribution the variance is $p(1-p)$\n",
    "\n",
    "Where p is the proabability of success."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Binomial distribution describes the number of successess of a set of bernouli trials. For example, say we have an unfair coin with a probability of landing heads of .8, if we designated our number of trials as 3, our PMF and CDF would look like what we see below:\n",
    "![](./images/binomial.png)\n",
    "\n",
    "The mean of this distribution is $n*p$\n",
    "\n",
    "The variance of this distribution is $n*p(1-p)$\n",
    "\n",
    "Where $n$ is the number of Bernoulli random variables and $p$ is the probability of one specific outcome \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity\n",
    "\n",
    "- Go to [Seeing Theory](https://seeing-theory.brown.edu/probability-distributions/index.html) and scroll to **Discrete and Continuous**.  \n",
    "- Now select **Discrete**.  \n",
    "- From the dropdown select **Bernoulli Distribution**.  \n",
    "- Check out the PMF and CDF of this distribution.  \n",
    "- Adjust the $p$ value.  What do you notice to the shape of this distribution?\n",
    "- Now do the same for the **Binomial Distribution**.  What do you notice as you adjust the value of $p$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normal distribution describes many phenomena. Think of anything that has a typical range:\n",
    "- human body temperatures\n",
    "- sizes of elephants\n",
    "- sizes of stars\n",
    "- populations of cities\n",
    "- IQ\n",
    "- Heart rate\n",
    "\n",
    "Among human beings, 98.6 degrees Fahrenheit is an _average_ body temperature. Many folks' temperatures won't measure _exactly_ 98.6 degrees, but most measurements will be _close_. It is much more common to have a body temperature close to 98.6 (whether slightly more or slightly less) than it is to have a body temperature far from 98.6 (whether significantly more or significantly less). This is a hallmark of a normally distributed variable.\n",
    "\n",
    "Similarly, there are large elephants and there are small elephants, but most elephants are near the average size.\n",
    "\n",
    "The normal distribution is _very_ common in nature and will arise often in your work. Get to know it well!\n",
    "\n",
    "You will recognize it by its characteristic bell curve. \n",
    "\n",
    "![normal_curve](https://www.simplypsychology.org/normal-distribution.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may see the notation \n",
    "\n",
    "$ N(Î¼,Ïƒ2)$\n",
    "\n",
    "where N signifies that the distribution is normal, Î¼ is the mean, and Ïƒ2 is the variance. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a plot of a normal distribution with a mean of 10 and a standard deviaiton of 2\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "mu = 10\n",
    "sigma = 2\n",
    "curve = np.linspace(stats.norm(mu,sigma).ppf(0.01),\n",
    "             stats.norm(mu,sigma).ppf(0.99), 100)\n",
    "ax.plot(curve, stats.norm(mu,sigma).pdf(curve),\n",
    "     'r-', lw=5, alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/normal_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn!\n",
    "\n",
    "Suppose the average height of an American woman is 65 inches with a standard deviation of 3.5 inches. Use numpy's random.normal to generate a sample of 1000 women and plot the histogram of the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **standard normal distribution** has a **mean of 0 and variance of 1**. This is also known as a z distribution. \n",
    "\n",
    "\n",
    "![norm_to_z](./images/norm_to_z.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's transform the normal distribtion centered on 5 with a standard deviation of 2 into a z curve\n",
    "normal_dist = np.random.normal(5,2,1000)\n",
    "z_dist = [(x - np.mean(normal_dist))/np.std(normal_dist) \n",
    "          for x in normal_dist]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.kdeplot(z_dist, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/empirical_rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Rule\n",
    "> The empirical or 68â€“95â€“99.7 states that 68% of the values of a normal distribution of data lie within 1 standard deviation of the mean, 95% within 2 stds, and 99.7 within three.  \n",
    "> The empirical rule has countless applications in data science, which we will expand upon in the next few lectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calculating the z-score of an individual point, we can see how unlikely a value is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Turn\n",
    "\n",
    "Consider, once again, the distribution of heights of American women, with a mean of 65 inches and a standard deviation of 3.5 inches.\n",
    "\n",
    "Calculate the z-score for a woman with a height of 76 inches. \n",
    "\n",
    "Based on the empirical rule, if you were sampling heights of American women, speculate as to how improbable would that height be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we need to know this again?\n",
    "\n",
    "- It is important to know what the underlying distribution of your data is.\n",
    "- Some statistical methods like many hypothesis tests assume that the data follows a normal distribution.\n",
    "- Linear regression models assume that the residuals follow a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other important Distributions\n",
    "\n",
    "[Chi-Squared](https://homepage.divms.uiowa.edu/~mbognar/applets/chisq.html)\n",
    "\n",
    "[Poisson](https://homepage.divms.uiowa.edu/~mbognar/applets/pois.html)\n",
    "\n",
    "[Gamma](https://en.wikipedia.org/wiki/Gamma_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
